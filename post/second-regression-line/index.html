<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta name=author content><meta name=description content="What is the slope of the second (x on y) regression line? It&rsquo;s obvious once you see it but it kept me stumped for a few hours."><link rel=icon href=https://www.codeandbugs.com/favicon.ico><meta name=keywords content=" hugo  latex  theme "><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code","option"]}}</script><script async defer src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js id=MathJax-script></script><meta property="og:title" content="The mystery of the second regression line"><meta property="og:description" content="What is the slope of the second (x on y) regression line? It&rsquo;s obvious once you see it but it kept me stumped for a few hours."><meta property="og:type" content="article"><meta property="og:url" content="https://www.codeandbugs.com/post/second-regression-line/"><meta property="article:section" content="post"><meta property="article:published_time" content="2023-10-05T08:29:19+02:00"><meta property="article:modified_time" content="2023-10-07T22:15:16+02:00"><link rel=canonical href=https://www.codeandbugs.com/post/second-regression-line/><meta itemprop=name content="The mystery of the second regression line"><meta itemprop=description content="What is the slope of the second (x on y) regression line? It&rsquo;s obvious once you see it but it kept me stumped for a few hours."><meta itemprop=datePublished content="2023-10-05T08:29:19+02:00"><meta itemprop=dateModified content="2023-10-07T22:15:16+02:00"><meta itemprop=wordCount content="907"><meta itemprop=keywords content="statistics,mathematics,"><link media=screen rel=stylesheet href=https://www.codeandbugs.com/css/common.css><link media=screen rel=stylesheet href=https://www.codeandbugs.com/css/content.css><title>The mystery of the second regression line - CodeAndBugs</title>
<meta name=twitter:card content="summary"><meta name=twitter:title content="The mystery of the second regression line"><meta name=twitter:description content="What is the slope of the second (x on y) regression line? It&rsquo;s obvious once you see it but it kept me stumped for a few hours."><link rel=stylesheet href=https://www.codeandbugs.com/css/single.css></head><body><div id=wrapper><header id=header><h1><a href=https://www.codeandbugs.com/>CodeAndBugs</a></h1><nav><span class=nav-bar-item><a class=link href=/>Post</a>
</span><span class=nav-bar-item><a class=link href=/post/>Archives</a>
</span><span class=nav-bar-item><a class=link href=/about/>About</a></span></nav></header><main id=main class=post><h1>The mystery of the second regression line</h1><div><b>Keywords: </b><a class=link href=https://www.codeandbugs.com/tags/statistics>#statistics</a>
<a class=link href=https://www.codeandbugs.com/tags/mathematics>#mathematics</a></div><article class=content><p>A few days ago I was stumped by a question that came up while studying Chapter
10 &ldquo;Regression&rdquo; of <em>Statistics</em> by Freedman, Pisani and Purves.</p><p>The context is regression with two variables.</p><p>Notation:</p><ul><li>σ (sigma) and SD: standard deviation</li><li>μ (mu): mean</li><li>r: Pearson correlation coefficient</li><li>x and y: the two variables</li><li>$\sigma_x$: standard deviation of x</li><li>$\mu_x$: mean of x</li></ul><p>Chapter 8 had introduced the concept of the <em>SD line</em>, which is the line that
crosses the point of means $(\mu_x,\mu_y)$ as well as
$(\mu_x+\sigma_x,\mu_y+\sigma_y)$, $(\mu_x-\sigma_x,\mu_y-\sigma_y)$,
$(\mu_x+2\cdot\sigma_x,\mu_y+2\cdot\sigma_y)$ and all other points that are an
equal number of SDs away from the point of means.</p><p>For example here is a scatter diagram of ficticious height and weight data with
the <em>SD line</em>. For those less familiar with the metric system, the mean
values 171cm and 87kg are about 5ft 7in and 192lb respectively.</p><p><img src=plot1.svg alt="Scatter plot with SD line" title="Scatter plot with SD line"></p><p>Chapter 8 also introduces the correlation coefficient $r$ which measures how
strong the linear association between the variables is. The closer it is to 1
(or -1) the stronger the variables are associated. In Chapter 9 we learn that
the correlation coefficient does not change if we interchange the variables.
That is, weight is as correlated with height as height is with weight.</p><p>In our example case $r = 0.462$</p><p>In Chapter 10 the idea of the regression line is introduced. The regression
line is a line that best fits the data, minimizing vertical distance to the
points. It allows to predict for each value of x (height) the mean value of
y (weight). The chapter also explains that the slope of the <em>SD line</em> is
$\frac{\sigma_y}{\sigma_x}$ and the slope of the regression line is
$r\frac{\sigma_y}{\sigma_x}$</p><p><img src=plot2.svg alt="Scatter plot with SD line and regression line" title="Scatter plot with
SD line and regression line"></p><p>This green regression line will tell you for each value of x (height) the mean
value of y (weight). If you divide the plot into columns, the regression line
aproximately passes through the mean y (weight) value within each column.</p><p>So far so good.</p><p>Then, however, we learn that there is a second regression line, namely the one
that for each value of $y$ (weight) predicts the mean value of $x$ (height). That
might sound similar, but is not the same thing. If you divide the plot into
rows, this second regression line will aproximately pass through the mean x
(height) value for each row.</p><p>The book gives no further details on how to calculate this second regression
line. What is its slope? We know that $r$ never changes and that the slope
must depend on $\sigma_x$ and $\sigma_y$ in some way. Therefore, it must be
$r\frac{\sigma_x}{\sigma_y}$, right? We just invert the standard deviations.</p><p>Let&rsquo;s plot the result.</p><p><img src=plot3.svg alt="Scatter plot with SD line, one correct and one incorrect regression
line" title="Scatter plot with SD line, one correct and one incorrect
regression line"></p><p>It looks off. In the examples in the book both regression lines were
symmetrical with respect to the <em>SD line</em>, whereas here the first regression
line is between the second regression line and the <em>SD line</em>. Also, the second
regression line is supposed to minimize the horizontal distance to the points.
If you look at the bottom of the graph you can see that the line is far away
from all points. The same is true for the top of the graph.</p><p>In the image below I have marked the points that are too far away from the
second (orange) regression line with red circles. Remember that now we are
trying to minimize the HORIZONTAL distance, which I have indicated with the
olive-green colored arrows.</p><p><img src=plot3_notes.svg alt="Scatter plot with SD line, one correct and one incorrect regression line as
well as some notes" title="Scatter plot with SD line, one correct and
one incorrect regression line as well as some notes"></p><p>So, what should we change? If we use $r\frac{\sigma_y}{\sigma_x}$ we get the
slope of the first regression line, which can&rsquo;t be right. And we know $r$
cannot change.</p><p>This is the mystery I was pondering. What is the slope given the above
constraints?</p><p>The solution to the mystery is that the second regression line calculates $x$
with respect to $y$. So the equation is $x = slope \cdot y + intercept$. And
here slope is precisely $r\frac{\sigma_x}{\sigma_y}$. If we re-order the terms
to have $y$ on the left hand as is usual we get $y = \frac{x -
intercept}{slope} = \frac{1}{slope}x - \frac{intercept}{slope}$</p><p>And $\frac{1}{slope}$ is the same as $\frac{1}{r} \cdot
\frac{\sigma_y}{\sigma_x}$ so the only thing that changes between the slopes of
the two regression lines is that the first one includes $r$ and the second one
$\frac{1}{r}$</p><p>We can now plot that line and voilà.</p><p><img src=plot4.svg alt="Scatter plot with SD line and two correct regression lines" title="Scatter plot with SD line and two correct regression lines"></p><p>The equation of the <em>SD line</em> is: $y = 1.38\cdot x - 149$</p><p>The equation of the first regression line (green) is: $y = 0.638\cdot x - 22$</p><p>The equation of the second regression line (orange) is: $y = 2.99\cdot x - 424$</p><p>You can verify for yourself that if you multiply $r$ by the slope of the <em>SD
line</em> (1.38) you&rsquo;ll get the slope of the first (green) regression line and if you
multiply $\frac{1}{r}$ by the slope of the <em>SD line</em> you&rsquo;ll get the slope of
the second (orange) regression line.</p><p>If we normalize the data (i.e. center on the mean and plot each point as the
number of SDs distance to the mean) then the slope of the <em>SD line</em> will always
be 1, the slope of the first regression line will be $r$ and the slope of the
second regression line $\frac{1}{r}$ (since both SDs are 1 by definition).</p><p><img src=plot5.svg alt="Scatter plot with SD line and two correct regression lines
(normalized)" title="Scatter plot with SD line and two correct regression
lines (normalized)"></p><p>The equations in the normalized plot are as follows.</p><p><em>SD line</em>: $y = x$</p><p>First regression line (green): $y = 0.462\cdot x$</p><p>Second regression line (orange): $y = 2.165\cdot x$</p><p>You can find the Python code used to generate the data and plots on GitHub:
<a href=https://gist.github.com/omarkohl/433968aa54d75e34a5c8b5c50a259ed7>https://gist.github.com/omarkohl/433968aa54d75e34a5c8b5c50a259ed7</a></p></article><div class=paginator><a class=link href=https://www.codeandbugs.com/post/statistical-discrimination/>← prev</a>
<a class=link href=https://www.codeandbugs.com/post/poker-theory-poker-night/>next →</a></div><div class=comment></div></main><footer id=footer><div><span>© 2015</span> - <span>2024</span></div><div class=footnote><span>Found a mistake? Send me a <a class=link href=https://github.com/omarkohl/codeandbugs.com target=_blank rel=noopener>pull request</a> or an <a class=link href=mailto:info@codeandbugs.com>e-mail</a>.</span></div></footer></div><link media=screen rel=stylesheet href=https://www.codeandbugs.com/custom.css></body></html>